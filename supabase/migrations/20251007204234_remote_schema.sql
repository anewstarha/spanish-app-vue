create table "public"."high_frequency_words" (
    "id" bigint generated by default as identity not null,
    "spanish_word" text not null,
    "chinese_translation" text,
    "frequency" integer not null default 0,
    "source_sentence" text,
    "category" text[],
    "user_id" uuid,
    "mastered" boolean not null default false,
    "ai_explanation" jsonb,
    "tags" text[]
);


alter table "public"."high_frequency_words" enable row level security;

create table "public"."profiles" (
    "id" uuid not null,
    "updated_at" timestamp with time zone,
    "last_sentence_id" bigint,
    "last_word_id" bigint,
    "nickname" text not null,
    "last_study_mode" text,
    "current_session_ids" bigint[],
    "current_session_progress" integer,
    "last_study_filters" jsonb,
    "last_quiz_filters" jsonb,
    "current_quiz_questions" jsonb,
    "current_quiz_progress" integer
);


alter table "public"."profiles" enable row level security;

create table "public"."quiz_attempts" (
    "id" bigint generated by default as identity not null,
    "user_id" uuid not null,
    "item_id" bigint not null,
    "item_type" text not null,
    "is_correct" boolean not null,
    "attempted_at" timestamp with time zone not null default now()
);


alter table "public"."quiz_attempts" enable row level security;

create table "public"."sentences" (
    "id" bigint generated by default as identity not null,
    "created_at" timestamp with time zone not null default now(),
    "spanish_text" text,
    "chinese_translation" text,
    "mastered" boolean,
    "notes" text,
    "ai_notes" jsonb,
    "category" text not null default 'sentence'::text,
    "user_id" uuid,
    "tags" text[]
);


alter table "public"."sentences" enable row level security;

create table "public"."study_log" (
    "id" bigint generated by default as identity not null,
    "created_at" timestamp with time zone not null default now(),
    "user_id" uuid not null,
    "item_id" bigint not null,
    "item_type" text not null
);


alter table "public"."study_log" enable row level security;

create table "public"."user_progress" (
    "id" bigint generated always as identity not null,
    "user_id" uuid not null,
    "sentence_id" bigint not null,
    "is_mastered" boolean not null default false,
    "is_studied" boolean default false,
    "last_studied_at" timestamp with time zone default now()
);


alter table "public"."user_progress" enable row level security;

CREATE UNIQUE INDEX high_frequency_words_pkey ON public.high_frequency_words USING btree (id);

CREATE UNIQUE INDEX high_frequency_words_spanish_word_key ON public.high_frequency_words USING btree (spanish_word);

CREATE UNIQUE INDEX high_frequency_words_user_id_spanish_word_key ON public.high_frequency_words USING btree (user_id, spanish_word);

CREATE INDEX idx_user_progress_sentence_id ON public.user_progress USING btree (sentence_id);

CREATE INDEX idx_user_progress_user_id ON public.user_progress USING btree (user_id);

CREATE UNIQUE INDEX profiles_pkey ON public.profiles USING btree (id);

CREATE UNIQUE INDEX quiz_attempts_pkey ON public.quiz_attempts USING btree (id);

CREATE UNIQUE INDEX sentences_pkey ON public.sentences USING btree (id);

CREATE UNIQUE INDEX study_log_pkey ON public.study_log USING btree (id);

CREATE UNIQUE INDEX study_log_user_id_item_id_item_type_key ON public.study_log USING btree (user_id, item_id, item_type);

CREATE UNIQUE INDEX user_progress_pkey ON public.user_progress USING btree (id);

CREATE UNIQUE INDEX user_progress_unique_user_sentence ON public.user_progress USING btree (user_id, sentence_id);

alter table "public"."high_frequency_words" add constraint "high_frequency_words_pkey" PRIMARY KEY using index "high_frequency_words_pkey";

alter table "public"."profiles" add constraint "profiles_pkey" PRIMARY KEY using index "profiles_pkey";

alter table "public"."quiz_attempts" add constraint "quiz_attempts_pkey" PRIMARY KEY using index "quiz_attempts_pkey";

alter table "public"."sentences" add constraint "sentences_pkey" PRIMARY KEY using index "sentences_pkey";

alter table "public"."study_log" add constraint "study_log_pkey" PRIMARY KEY using index "study_log_pkey";

alter table "public"."user_progress" add constraint "user_progress_pkey" PRIMARY KEY using index "user_progress_pkey";

alter table "public"."high_frequency_words" add constraint "high_frequency_words_spanish_word_key" UNIQUE using index "high_frequency_words_spanish_word_key";

alter table "public"."high_frequency_words" add constraint "high_frequency_words_user_id_fkey" FOREIGN KEY (user_id) REFERENCES auth.users(id) ON DELETE CASCADE not valid;

alter table "public"."high_frequency_words" validate constraint "high_frequency_words_user_id_fkey";

alter table "public"."high_frequency_words" add constraint "high_frequency_words_user_id_spanish_word_key" UNIQUE using index "high_frequency_words_user_id_spanish_word_key";

alter table "public"."profiles" add constraint "nickname_length" CHECK (((char_length(nickname) >= 2) AND (char_length(nickname) <= 50))) not valid;

alter table "public"."profiles" validate constraint "nickname_length";

alter table "public"."profiles" add constraint "profiles_id_fkey" FOREIGN KEY (id) REFERENCES auth.users(id) ON DELETE CASCADE not valid;

alter table "public"."profiles" validate constraint "profiles_id_fkey";

alter table "public"."profiles" add constraint "profiles_last_sentence_id_fkey" FOREIGN KEY (last_sentence_id) REFERENCES sentences(id) ON DELETE SET NULL not valid;

alter table "public"."profiles" validate constraint "profiles_last_sentence_id_fkey";

alter table "public"."profiles" add constraint "profiles_last_word_id_fkey" FOREIGN KEY (last_word_id) REFERENCES high_frequency_words(id) ON DELETE SET NULL not valid;

alter table "public"."profiles" validate constraint "profiles_last_word_id_fkey";

alter table "public"."quiz_attempts" add constraint "quiz_attempts_item_type_check" CHECK ((item_type = ANY (ARRAY['sentence'::text, 'word'::text]))) not valid;

alter table "public"."quiz_attempts" validate constraint "quiz_attempts_item_type_check";

alter table "public"."quiz_attempts" add constraint "quiz_attempts_user_id_fkey" FOREIGN KEY (user_id) REFERENCES auth.users(id) ON DELETE CASCADE not valid;

alter table "public"."quiz_attempts" validate constraint "quiz_attempts_user_id_fkey";

alter table "public"."sentences" add constraint "sentences_user_id_fkey" FOREIGN KEY (user_id) REFERENCES auth.users(id) ON DELETE CASCADE not valid;

alter table "public"."sentences" validate constraint "sentences_user_id_fkey";

alter table "public"."study_log" add constraint "study_log_user_id_fkey" FOREIGN KEY (user_id) REFERENCES auth.users(id) ON DELETE CASCADE not valid;

alter table "public"."study_log" validate constraint "study_log_user_id_fkey";

alter table "public"."study_log" add constraint "study_log_user_id_item_id_item_type_key" UNIQUE using index "study_log_user_id_item_id_item_type_key";

alter table "public"."user_progress" add constraint "user_progress_sentence_id_fkey" FOREIGN KEY (sentence_id) REFERENCES sentences(id) ON DELETE CASCADE not valid;

alter table "public"."user_progress" validate constraint "user_progress_sentence_id_fkey";

alter table "public"."user_progress" add constraint "user_progress_unique_user_sentence" UNIQUE using index "user_progress_unique_user_sentence";

alter table "public"."user_progress" add constraint "user_progress_user_id_fkey" FOREIGN KEY (user_id) REFERENCES auth.users(id) ON DELETE CASCADE not valid;

alter table "public"."user_progress" validate constraint "user_progress_user_id_fkey";

set check_function_bodies = off;

CREATE OR REPLACE FUNCTION public.batch_update_tags(p_sentence_ids bigint[], p_tags_to_add text[], p_tags_to_remove text[])
 RETURNS void
 LANGUAGE plpgsql
AS $function$
DECLARE
    sentence_id BIGINT;
    current_tags TEXT[];
BEGIN
    -- 确保只有当前登录的用户可以执行此操作
    IF auth.uid() IS NULL THEN
        RAISE EXCEPTION '用户未认证';
    END IF;

    FOREACH sentence_id IN ARRAY p_sentence_ids
    LOOP
        -- 获取当前句子的标签，并锁定该行以防止并发问题
        SELECT tags INTO current_tags FROM sentences
        WHERE id = sentence_id AND user_id = auth.uid()
        FOR UPDATE;

        -- 如果句子存在且属于该用户
        IF FOUND THEN
            -- 1. 添加新标签
            IF array_length(p_tags_to_add, 1) > 0 THEN
                -- 使用 unnest 和 distinct 来合并和去重
                SELECT array_agg(DISTINCT t)
                INTO current_tags
                FROM unnest(current_tags || p_tags_to_add) AS t;
            END IF;

            -- 2. 移除要删除的标签
            IF array_length(p_tags_to_remove, 1) > 0 THEN
                SELECT array_agg(t)
                INTO current_tags
                FROM unnest(current_tags) AS t
                WHERE NOT (t = ANY(p_tags_to_remove));
            END IF;

            -- 3. 更新数据库中的标签
            UPDATE sentences
            SET tags = current_tags
            WHERE id = sentence_id;
        END IF;
    END LOOP;
END;
$function$
;

CREATE OR REPLACE FUNCTION public.get_all_user_tags(p_user_id uuid)
 RETURNS TABLE(tag text)
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public'
AS $function$
DECLARE
    public_user_id UUID;
BEGIN
    SELECT u.id INTO public_user_id FROM auth.users u WHERE u.email = 'chenlongfei@outlook.com';
    RETURN QUERY
    SELECT DISTINCT unnest(s.tags) AS tag
    FROM sentences s
    WHERE 
        (s.user_id = public_user_id OR s.user_id = p_user_id)
        AND s.tags IS NOT NULL AND array_length(s.tags, 1) > 0
    ORDER BY tag;
END;
$function$
;

CREATE OR REPLACE FUNCTION public.get_home_statistics()
 RETURNS jsonb
 LANGUAGE plpgsql
 SECURITY DEFINER
AS $function$
DECLARE
  stats JSONB;
  current_user_id UUID := auth.uid();
  streak INT;
BEGIN
  -- 计算连续学习天数 (Study Streak)
  WITH daily_activity AS (
    SELECT DISTINCT last_studied_at::date as activity_date
    FROM public.user_progress
    WHERE user_id = current_user_id
  ),
  date_series AS (
    SELECT
      activity_date,
      -- 通过减去行号天数，为连续的日期创建分组ID
      activity_date - (ROW_NUMBER() OVER (ORDER BY activity_date DESC))::int * interval '1 day' as date_group
    FROM daily_activity
    WHERE activity_date <= NOW()::date
  )
  SELECT COUNT(*)::int INTO streak
  FROM date_series
  WHERE date_group = (
    -- 获取最近一次活动的分组ID
    SELECT date_group FROM date_series ORDER BY activity_date DESC LIMIT 1
  )
  -- 并且，必须确保最近一次活动是今天或昨天，否则视为中断
  AND (SELECT MAX(activity_date) FROM date_series) >= (NOW()::date - interval '1 day');

  -- 构建最终的JSON结果
  SELECT jsonb_build_object(
    'streak', COALESCE(streak, 0), -- 添加 streak 字段
    'progress', (
      SELECT jsonb_build_object(
        'mastered', COUNT(*) FILTER (WHERE up.is_mastered = true),
        'studied', COUNT(*) FILTER (WHERE up.is_mastered = false AND up.is_studied = true),
        'unstudied', COUNT(*) FILTER (WHERE up.id IS NULL)
      )
      FROM public.sentences s
      LEFT JOIN public.user_progress up ON s.id = up.sentence_id AND up.user_id = current_user_id
      WHERE s.user_id = current_user_id
    )
  ) INTO stats;
  
  RETURN stats;
END;
$function$
;

CREATE OR REPLACE FUNCTION public.get_user_sentences_with_progress(p_user_id uuid)
 RETURNS TABLE(id bigint, spanish_text text, chinese_translation text, tags text[], is_mastered boolean, is_studied boolean, is_public boolean)
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public'
AS $function$
DECLARE
    public_user_id UUID;
BEGIN
    SELECT u.id INTO public_user_id FROM auth.users u WHERE u.email = 'chenlongfei@outlook.com';
    RETURN QUERY
    SELECT
        s.id,
        s.spanish_text,
        s.chinese_translation,
        s.tags,
        COALESCE(up.is_mastered, false) as is_mastered,
        (up.id IS NOT NULL) as is_studied,
        (s.user_id = public_user_id) as is_public
    FROM
        sentences s
    LEFT JOIN
        user_progress up ON s.id = up.sentence_id AND up.user_id = p_user_id
    WHERE
        s.user_id = public_user_id OR s.user_id = p_user_id;
END;
$function$
;

CREATE OR REPLACE FUNCTION public.handle_new_user()
 RETURNS trigger
 LANGUAGE plpgsql
 SECURITY DEFINER
 SET search_path TO 'public'
AS $function$
begin
  insert into public.profiles (id, nickname)
  values (
    new.id,
    -- 从 new.raw_user_meta_data 这个 JSON 对象中提取 nickname 字段的值
    -- 如果元数据中没有 nickname，则回退为'新用户'，以确保不违反 NOT NULL 约束
    coalesce(new.raw_user_meta_data->>'nickname', '新用户')
  );
  return new;
end;
$function$
;

CREATE OR REPLACE FUNCTION public.update_user_word_frequency(p_user_id uuid, p_words_to_add text[], p_words_to_remove text[])
 RETURNS void
 LANGUAGE plpgsql
 SECURITY DEFINER
AS $function$
begin
  -- 1. 处理要增加的单词
  -- 使用 on conflict 一次性完成插入新词和增加旧词频率的操作
  insert into high_frequency_words (user_id, spanish_word, frequency)
  select
    p_user_id,
    word,
    1
  from unnest(p_words_to_add) as t(word)
  on conflict (user_id, spanish_word) do update
  set frequency = high_frequency_words.frequency + 1;

  -- 2. 处理要移除的单词
  -- 2.1. 降低频率
  update high_frequency_words
  set frequency = frequency - 1
  where
    user_id = p_user_id
    and spanish_word = any(p_words_to_remove);

  -- 2.2. 删除频率为 0 或以下的单词
  delete from high_frequency_words
  where
    user_id = p_user_id
    and frequency <= 0;
    
end;
$function$
;

create policy "Users can delete their own words"
on "public"."high_frequency_words"
as permissive
for delete
to authenticated
using ((auth.uid() = user_id));


create policy "Users can insert their own words"
on "public"."high_frequency_words"
as permissive
for insert
to authenticated
with check ((auth.uid() = user_id));


create policy "Users can read their own words"
on "public"."high_frequency_words"
as permissive
for select
to authenticated
using ((auth.uid() = user_id));


create policy "Users can update their own words"
on "public"."high_frequency_words"
as permissive
for update
to authenticated
using ((auth.uid() = user_id))
with check ((auth.uid() = user_id));


create policy "Enable read access for own user"
on "public"."profiles"
as permissive
for select
to authenticated
using ((auth.uid() = id));


create policy "Public profiles are viewable by everyone."
on "public"."profiles"
as permissive
for select
to public
using (true);


create policy "Users can insert their own profile."
on "public"."profiles"
as permissive
for insert
to public
with check ((auth.uid() = id));


create policy "Users can update their own profile."
on "public"."profiles"
as permissive
for update
to public
using ((auth.uid() = id));


create policy "Users can insert their own quiz attempts"
on "public"."quiz_attempts"
as permissive
for insert
to authenticated
with check ((auth.uid() = user_id));


create policy "Users can view their own quiz attempts"
on "public"."quiz_attempts"
as permissive
for select
to authenticated
using ((auth.uid() = user_id));


create policy "Users can delete their own sentences"
on "public"."sentences"
as permissive
for delete
to authenticated
using ((auth.uid() = user_id));


create policy "Users can insert their own sentences"
on "public"."sentences"
as permissive
for insert
to authenticated
with check ((auth.uid() = user_id));


create policy "Users can read their own sentences"
on "public"."sentences"
as permissive
for select
to authenticated
using ((auth.uid() = user_id));


create policy "Users can update their own sentences"
on "public"."sentences"
as permissive
for update
to authenticated
using ((auth.uid() = user_id))
with check ((auth.uid() = user_id));


create policy "Users can manage their own study log"
on "public"."study_log"
as permissive
for all
to public
using ((auth.uid() = user_id))
with check ((auth.uid() = user_id));


create policy "Users can manage their own progress"
on "public"."user_progress"
as permissive
for all
to public
using ((auth.uid() = user_id))
with check ((auth.uid() = user_id));



CREATE TRIGGER on_auth_user_created AFTER INSERT ON auth.users FOR EACH ROW EXECUTE FUNCTION handle_new_user();

drop trigger if exists "objects_delete_cleanup" on "storage"."objects";

drop trigger if exists "objects_update_cleanup" on "storage"."objects";

drop trigger if exists "prefixes_delete_cleanup" on "storage"."prefixes";

CREATE TRIGGER objects_delete_delete_prefix AFTER DELETE ON storage.objects FOR EACH ROW EXECUTE FUNCTION storage.delete_prefix_hierarchy_trigger();

CREATE TRIGGER objects_update_create_prefix BEFORE UPDATE ON storage.objects FOR EACH ROW WHEN (((new.name <> old.name) OR (new.bucket_id <> old.bucket_id))) EXECUTE FUNCTION storage.objects_update_prefix_trigger();

CREATE TRIGGER prefixes_delete_hierarchy AFTER DELETE ON storage.prefixes FOR EACH ROW EXECUTE FUNCTION storage.delete_prefix_hierarchy_trigger();


